import configparser
from pathlib import Path
from neo4j import GraphDatabase
import requests
import time
import random

# BASE_DIR should point to project root: /home/robert/insightViewer/source/InsightViewer
BASE_DIR = Path(__file__).resolve().parents[3]
CONFIG_PATH = BASE_DIR.parent / "config.ini"

config = configparser.ConfigParser()
print("Using config:", CONFIG_PATH)  # optional debug
if not CONFIG_PATH.exists():
    raise RuntimeError(f"Config file not found: {CONFIG_PATH}")

config.read(CONFIG_PATH)



NEO4J_URI = config['NEO4J']['URI']
NEO4J_USER = config['NEO4J']['USERNAME']
NEO4J_PASSWORD = config['NEO4J']['PASSWORD']


OLLAMA_URL = config['OLLAMA']['BASE']
EMBED_MODEL = config['OLLAMA']['EMB_MODEL']
#MODEL = config['OLLAMA']['MODEL']

BATCH_SIZE = 25
SLEEP = 0.05  # be nice to Ollama

MAX_CHARS = 1200  # was 6000; keep well below model context

def split_text(text: str, max_chars: int = MAX_CHARS) -> list[str]:
    text = (text or "").strip()
    if len(text) <= max_chars:
        return [text] if text else []
    parts = []
    buf = []
    size = 0
    for para in text.split("\n\n"):
        para = para.strip()
        if not para:
            continue
        if len(para) > max_chars:
            # hard split huge paragraph â€“ also clamp just in case
            for i in range(0, len(para), max_chars):
                parts.append(para[i:i+max_chars])
            continue
        if size + len(para) + 2 > max_chars:
            parts.append("\n\n".join(buf))
            buf, size = [para], len(para)
        else:
            buf.append(para)
            size += len(para) + 2
    if buf:
        parts.append("\n\n".join(buf))
    return parts

def embed_long(text: str) -> list[float]:
    chunks = split_text(text)
    if not chunks:
        return []
    vecs = [embed(c) for c in chunks]
    # average vectors
    dim = len(vecs[0])
    out = [0.0]*dim
    for v in vecs:
        for i, x in enumerate(v):
            out[i] += float(x)
    n = float(len(vecs))
    return [x/n for x in out]


def embed(text: str) -> list[float]:
    text = (text or "").strip()
    if not text:
        return []

    if len(text) > MAX_CHARS:
        text = text[:MAX_CHARS]

    for attempt in range(3):
        r = requests.post(
            f"{OLLAMA_URL}/api/embed",
            json={"model": EMBED_MODEL, "input": text},
            timeout=120,
        )
        if r.ok:
            j = r.json()
            return j["embeddings"][0]

        print(f"Embed error (attempt {attempt+1}/3): {r.status_code} {r.text}")
        time.sleep(1 + random.random())

    raise RuntimeError(
        f"Ollama {r.status_code}: {r.text}\n"
        f"Sent chars={len(text)} model={EMBED_MODEL} url={OLLAMA_URL}"
    )


driver = GraphDatabase.driver(
    NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD)
)

with driver.session() as session:
    while True:
        rows = session.run("""
            MATCH (c:Chunk)
            WHERE c.text IS NOT NULL AND c.embedding IS NULL
            RETURN c.id_rc AS id, c.text AS text
            LIMIT $limit
        """, limit=BATCH_SIZE).data()

        if not rows:
            break

        for row in rows:
            vec = embed_long(row["text"])
            session.run("""
                MATCH (c:Chunk {id_rc:$id})
                SET c.embedding = $vec
            """, id=row["id"], vec=vec)

            print("Embedded:", row["id"], "dim:", len(vec))
            time.sleep(SLEEP)

print("All chunks embedded.")
